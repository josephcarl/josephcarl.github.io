<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Joseph Carl</title>
    <link>https://josephcarl.github.io/post/index.xml</link>
    <description>Recent content in Posts on Joseph Carl</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 19 Sep 2017 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://josephcarl.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Visualizing Seattle Bike Collisions</title>
      <link>https://josephcarl.github.io/2017/09/visualizing-seattle-bike-collisions/</link>
      <pubDate>Tue, 19 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://josephcarl.github.io/2017/09/visualizing-seattle-bike-collisions/</guid>
      <description>&lt;p&gt;It’s been a while since my last update. I’ve wanted to share a small project I’ve been working on over the past few months! As an avid cyclist, I love biking around Seattle, whether it’s heading to class, work, or just running errands. I live in Ballard near the Burke Gilman Trail, one of the flatter parts of Seattle, so I can often avoid Seattle’s notorious hills. While Seattle is great for biking compared to other cities, its bike infrastructure could definitely be improved. One way to assess bike facilities and look for new opportunities is to study bicycle collision data to identify hotspots and trends. Additionally, for the city to meet its Vision Zero goals of having no serious injuries or traffic fatalities, it needs to understand where and how collisions are happening. Fortunately, the City of Seattle makes all of this data available online! Below I will share some of my findings from this analysis.&lt;/p&gt;
&lt;div id=&#34;data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Data&lt;/h2&gt;
&lt;p&gt;The dataset comes from &lt;a href=&#34;https://data.seattle.gov/d/v7k9-7dn4?category=Transportation&amp;amp;view_name=SDOT-Collisions&#34;&gt;data.seattle.gov&lt;/a&gt;, where all collision data in the City of Seattle is collected by the Seattle Department of Transportation (SDOT) and posted. Though the data appears as a map with points, it can be downloaded as a csv for analysis. Since I am looking only at collisions involving bicycles, I filtered only the observations where &lt;code&gt;COLLISIONTYPE&lt;/code&gt; is “Cycles”. I downloaded this dataset in March 2017 originally, so it does not have summer 2017 data included in it.&lt;/p&gt;
&lt;p&gt;You can find the filtered dataset and source code for this analysis on &lt;a href=&#34;https://github.com/josephcarl/Seattle-Biking&#34;&gt;my Github page&lt;/a&gt;.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Set working directory
setwd(&amp;quot;~/Documents/R Files/Seattle Biking&amp;quot;)

# Libraries
library(ggplot2)
library(readr)
library(dplyr)
library(lubridate)
library(ggmap)

# Read in data file
bikedat &amp;lt;- read_csv(&amp;quot;SDOT_Collisions.csv&amp;quot;, guess_max = 1500)

# Convert incident date, incident time to date and time classes
bikedat$INCDATE &amp;lt;- mdy_hms(bikedat$INCDATE)
bikedat$INCDTTM &amp;lt;- parse_date_time(bikedat$INCDTTM, orders = &amp;quot;mdy IMS p&amp;quot;)

# Extract latitude and longitude from shape variable
  # Lat: take substring of Shape variable
bikedat$Lat &amp;lt;- as.numeric(substr(bikedat$Shape, start = 2, stop = 18))
  # Long: Split Shape at &amp;quot;, &amp;quot; and unlist (lapply) to get 2nd element,
  # then take substring to trim the &amp;quot;)&amp;quot; and convert to numeric
bikedat$Long &amp;lt;- as.numeric(substr(lapply(strsplit(bikedat$Shape, &amp;quot;, &amp;quot;), &amp;#39;[&amp;#39;, 2), start=0, stop = 13))&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;div id=&#34;where-are-collisions-occurring&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Where Are Collisions Occurring?&lt;/h2&gt;
&lt;p&gt;For some initial exploration, I played around with mapping the data using &lt;code&gt;ggmap&lt;/code&gt; and the latitude and longitude information in the dataset. One thing I found interesting is that the vast majority of bike collisions actually happened during daylight. I expected there to be more collisions at dark or dawn/dusk, when there is less light to see cyclists. However, there is also usually more traffic on the road during the day, so there are more chances of a collision occurring. The following map shows the distribution of collisions in 2017. It looks like most collisions happen downtown and in the central neighborhoods.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Get Seattle map data
seamap &amp;lt;- get_map(&amp;quot;Seattle&amp;quot;, maptype = &amp;quot;roadmap&amp;quot;, zoom = 11)

# Map of 2016 collisions, colored by time of day
m.2016 &amp;lt;- ggmap(seamap) +
  geom_point(aes(x=Long, y=Lat, color=factor(LIGHTCOND)), data = bikedat[year(bikedat$INCDATE)==2016,])+
  labs(title = &amp;quot;Most Collisions in 2016 Happened During Daylight&amp;quot;,
       color=&amp;quot;Light Conditions&amp;quot;)
m.2016&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://josephcarl.github.io/post/2017-09-19-seattle-biking1-rmd_files/figure-html/unnamed-chunk-2-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;who-ran-into-whom&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Who Ran Into Whom?&lt;/h1&gt;
&lt;p&gt;Another thing I wondered about was who usually hit whom during a collision. SDOT actually provides this information with the “SDOT Collision Code”. There are several dozen collision codes, but they can be combined into a few main categories: a vehicle in operation hit someone else, a driverless vehicle hit someone, a cyclist hit someone else, a pedestrian or non-traffic cyclist hit someone, or a pedestrian hit someone. Using this information, I created the &lt;code&gt;Striker&lt;/code&gt; variable to make it easier to organize the observations. While this variable does not say who is legally at fault for a collision, it does answer the question of “who ran into whom” for a given collision.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Create variable &amp;quot;Striker&amp;quot; to describe &amp;quot;Who Hit Whom&amp;quot;, which can be determined from SDOT collision code
  # dplyr&amp;#39;s case_when() is useful for a more readable if-else syntax
bikedat &amp;lt;- bikedat %&amp;gt;% 
  mutate(Striker = factor(case_when(.$SDOT_COLCODE &amp;gt;= 10 &amp;amp; .$SDOT_COLCODE &amp;lt;= 29 ~ &amp;quot;Vehicle in Operation&amp;quot;,
                                    .$SDOT_COLCODE &amp;gt;= 30 &amp;amp; .$SDOT_COLCODE &amp;lt;= 49 ~ &amp;quot;Driverless Vehicle&amp;quot;,
                                    .$SDOT_COLCODE &amp;gt;= 50 &amp;amp; .$SDOT_COLCODE &amp;lt;= 69 ~ &amp;quot;Cyclist&amp;quot;,
                                    .$SDOT_COLCODE &amp;gt;= 70 &amp;amp; .$SDOT_COLCODE &amp;lt;= 76 ~ &amp;quot;Pedestrian or Non-Traffic Cyclist&amp;quot;,
                                    .$SDOT_COLCODE &amp;gt;= 80 ~ &amp;quot;Pedestrian Struck&amp;quot;,
                                    TRUE ~ as.character(NA))))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;From mapping the data and zooming in just on my neighborhood of Ballard and the other neighborhoods of Northwest Seattle, we can see a few interesting findings. First off, it looks like most collisions occur on arterial streets, such as 8th Ave NW, 15th Ave NW, NW 85th Street, Leary Way, and Nickerson St. Additionally, the majority of collisions involved a vehicle in operation striking a cyclist. However, there are still a decent amount of collisions where the striker was a cyclist hitting someone else. Only a few observations had missing (NA) data, and no collisions were caused by a driverless vehicle.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://josephcarl.github.io/post/2017-09-19-seattle-biking1-rmd_files/figure-html/unnamed-chunk-4-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;div id=&#34;how-are-collisions-changing-over-time&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;How are Collisions Changing Over Time?&lt;/h2&gt;
&lt;p&gt;This made me wonder about whether these collisions are changing over time. Unfortunately, the number of collisions is on an upward trend, as is the proportion of collisions where the striker is a vehicle.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;bikedat %&amp;gt;% group_by(year(INCDATE), Striker) %&amp;gt;% 
  summarise(n = n()) %&amp;gt;% 
  rename(year = `year(INCDATE)`) %&amp;gt;% 
  ggplot(aes(x=year, y=n, fill=Striker))+
  geom_col()+
  labs(y=&amp;quot;Number of Collisions&amp;quot;,
        x=&amp;quot;Year&amp;quot;,
       title=&amp;quot;Collisions Have Increased Over Time&amp;quot;,
       subtitle=&amp;quot;Proportion of collisions Caused by Vehicles Increasing&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://josephcarl.github.io/post/2017-09-19-seattle-biking1-rmd_files/figure-html/unnamed-chunk-5-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;bikedat %&amp;gt;% group_by(year(INCDATE), Striker) %&amp;gt;% 
  summarise(n = n()) %&amp;gt;% 
  rename(year = `year(INCDATE)`) %&amp;gt;% 
  ggplot(aes(x=year, y=n, fill=Striker))+
  geom_col(position = &amp;quot;fill&amp;quot;)+
  labs(y=&amp;quot;Proportion of Collisions&amp;quot;,
       x=&amp;quot;Year&amp;quot;,
       title=&amp;quot;Collisions Have Increased Over Time&amp;quot;,
       subtitle=&amp;quot;Proportion of collisions Caused by Vehicles Increasing&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://josephcarl.github.io/post/2017-09-19-seattle-biking1-rmd_files/figure-html/unnamed-chunk-5-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;p&gt;This upward trend may be driven in part by the fact that Seattle’s population is booming, so the number of cars and bikes on the road has increased. This means there are simply more opportunities for a collision to occur. However, the rising number of collisions suggest that the status quo will not suffice if the city wants to meet its Vision Zero goals. I’m a big fan of protected bike lanes, which can greatly reduce the risk of an accident on a given street compared to riding a bike in a bike lane or mixed with traffic.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;where-on-the-street-do-most-accidents-occur&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Where on the Street Do Most Accidents Occur?&lt;/h1&gt;
&lt;p&gt;Perhaps not surprisingly, the most common location for a collision is at an intersection. About half of all collisions occur at an intersection, followed by mid-block, not related to an intersection. We can also see that these two collision types also make up most of the increase in collisions over the past several years, as other junction types for collisions have stayed relatively flat.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;bikedat %&amp;gt;% group_by(year(INCDATE), JUNCTIONTYPE) %&amp;gt;% 
  summarise(n = n()) %&amp;gt;% 
  rename(year = `year(INCDATE)`) %&amp;gt;% 
  ggplot(aes(x=year, y=n, group=JUNCTIONTYPE, color=JUNCTIONTYPE))+
  geom_line()+
  labs(y=&amp;quot;Number of Collisions&amp;quot;,
       x=&amp;quot;Year&amp;quot;,
       color=&amp;quot;Junction Type&amp;quot;,
       title=&amp;quot;Most Collisions Are At Intersections&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://josephcarl.github.io/post/2017-09-19-seattle-biking1-rmd_files/figure-html/unnamed-chunk-6-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;div id=&#34;does-weather-play-a-role-in-collisions&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Does Weather Play a Role in Collisions?&lt;/h2&gt;
&lt;p&gt;Though Seattle is generally known as a dark, wet, and rainy city, I wondered if those same conditions play into whether a collision occurs. As noted above, most collisions actually occur during the day, not when it’s dark out. Perhaps surprisingly, the following graphs also show that about 75% of collisions happen when the weather is clear or partly cloudy or when the road is dry. There is a noticeable subset of observations that occur in wet conditions and when it is overcast or raining, and relatively few collisions in other conditions. Perhaps it is not surprising that there are more collisions in favorable weather conditions, as there are many more people biking on nice weather days than in the cold, dark winter months!&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;bikedat %&amp;gt;% group_by(year(INCDATE), ROADCOND) %&amp;gt;% 
  summarise(n = n()) %&amp;gt;% 
  rename(year = `year(INCDATE)`) %&amp;gt;% 
  ggplot(aes(x=year, y=n, fill=ROADCOND))+
  geom_col(position = &amp;quot;fill&amp;quot;)+
  labs(y=&amp;quot;Proportion of Accidents&amp;quot;,
       title=&amp;quot;Most Accidents Have Dry Road Conditions&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://josephcarl.github.io/post/2017-09-19-seattle-biking1-rmd_files/figure-html/unnamed-chunk-7-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;bikedat %&amp;gt;% group_by(year(INCDATE), WEATHER) %&amp;gt;% 
  summarise(n = n()) %&amp;gt;% 
  rename(year = `year(INCDATE)`) %&amp;gt;% 
  ggplot(aes(x=year, y=n, fill=WEATHER))+
  geom_col(position = &amp;quot;fill&amp;quot;)+
  labs(y=&amp;quot;Proportion of Accidents&amp;quot;,
       title=&amp;quot;Most Accidents Have Clear Weather Conditions&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;https://josephcarl.github.io/post/2017-09-19-seattle-biking1-rmd_files/figure-html/unnamed-chunk-7-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;conclusion-and-further-exploration&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Conclusion and Further Exploration&lt;/h2&gt;
&lt;p&gt;These are some of my main findings for collision data involving bikes in Seattle. Some of the main takeaways are that you should be extra careful when biking along arterials, at intersections, or during rush hour when the chance of a collision is higher. And always wear a helmet! Though I know it can be a divisive issue, I’m firmly in the camp that I would rather put up with the inconvenience or discomfort of a helmet than risk a head injury without one.&lt;/p&gt;
&lt;p&gt;I’m hoping to spend some more time with this data and do a deeper dive into what factors can help explain collisions. For example, looking just at collisions at intersections may be associated with different weather and road conditions, time of day, striker, and other factors than collisions occurring mid-block. I will have to save that exploration for another blog post!&lt;/p&gt;
&lt;p&gt;Additionally, since I originally downloaded this data in March, the launch of new bikesharing companies Spin, Limebike, and Ofo in Seattle are not included in this analysis. I definitely want to keep exploring this data and see if there is a noticeable change in collision data from the rise in new bikeshare companies.&lt;/p&gt;
&lt;p&gt;As mentioned above, you can find the filtered dataset and source code for this analysis and some other visualizations on &lt;a href=&#34;https://github.com/josephcarl/Seattle-Biking&#34;&gt;my Github page&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>My Experience at the Cascadia R Conference</title>
      <link>https://josephcarl.github.io/2017/06/my-experience-at-the-cascadia-r-conference/</link>
      <pubDate>Sun, 18 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>https://josephcarl.github.io/2017/06/my-experience-at-the-cascadia-r-conference/</guid>
      <description>&lt;p&gt;The past few weeks have been crazy with finishing final projects and taking final exams for spring quarter. This past week I also took a much-needed break between quarters for a road trip to the Canadian Rockies! I enjoyed recharging with some great hiking around Banff and Kootenay National Parks and checking out the natural hot springs at Radium Hot Springs. Plus, because Canada is celebrating its 150th birthday this year, admission to the parks was free!&lt;/p&gt;

&lt;p&gt;Here&amp;rsquo;s one of my favorite photos of the trip, taken at Stanley Glacier in Kootenay National Park, BC:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://josephcarl.github.io/img/stanley_glacier.jpeg&#34; alt=&#34;Stanley Glacier in Kootenay National Park&#34; /&gt;&lt;/p&gt;

&lt;p&gt;With all that going on, I haven&amp;rsquo;t had a chance to write about the &lt;a href=&#34;https://cascadiarconf.com/&#34;&gt;Cascadia R Conference&lt;/a&gt;, which happened for the first time on June 3 in Portland, OR.&lt;/p&gt;

&lt;p&gt;Overall, the conference was very well done, particularly considering it was organized in just a few months. Almost 200 people attended the conference. As a student, I appreciated that it took place on a Saturday, so I did not have to worry about missing class, and that student tickets were only $5, which made the decision to attend really easy. The Collaborative Life Sciences building at OHSU was a great space to have the conference, both in terms of its central location as well as its facilities.&lt;/p&gt;

&lt;p&gt;My favorite part of the conference was the &lt;code&gt;purrr&lt;/code&gt; workshop put on by Charlotte Wickham. She is great at explaining concepts, plus made the workshop interactive with lots of opportunities to learn by doing. The workshop mostly focused on using the &lt;code&gt;map()&lt;/code&gt; function and its related functions (&lt;code&gt;map_int()&lt;/code&gt;, &lt;code&gt;map_lgl()&lt;/code&gt;, &lt;code&gt;map_dbl()&lt;/code&gt;, etc.) to iterate over objects. It also introduced &lt;code&gt;map_2()&lt;/code&gt; and &lt;code&gt;walk()&lt;/code&gt; for iterating over multiple arguments and using functions for their side-effects like saving or displaying graphs. I will definitely be using these functions more in the future!&lt;/p&gt;

&lt;p&gt;The full-length and lightning talks were also quite interesting. It seemed that most of the talks (at least the ones I attended) were either academic or health research-focused. While it was interesting to see how R is used in these areas, some talks were harder to follow simply because I did not have the domain knowledge needed to understand the topic. There were few industry-focused speakers. Based on the people I met, it seemed like a decent amount attending the conference were working for businesses as data analysts or data scientists, but few presentations had a business focus for applications of R. Perhaps this just means the people working in industry did not submit as many talk proposals as the people working in academia or health research. Hopefully next year, I can submit a talk proposal about my own work in whatever job I have and change that trend! Either way, it was still exciting to see the wide variety in which people use R in their respective fields.&lt;/p&gt;

&lt;p&gt;As for my own lightning talk about building this website with the &lt;code&gt;blogdown&lt;/code&gt; package and Github Pages, it also went really well. It was exciting to share what I have learned about building this site, plus made for great public speaking practice. A few people even told me at the end of the day they are now interested in building their own personal websites using R! If you would like to see the slides for my presentation, you can view them &lt;a href=&#34;https://josephcarl.github.io/slides/JoeCarl-CascadiaRConf-Slides&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Tomorrow is the first day of summer quarter, which is the final quarter of my master&amp;rsquo;s program. I&amp;rsquo;ll be doing my capstone project as well as one other course. It&amp;rsquo;s hard to believe I&amp;rsquo;m only 8 weeks from being done with the program. I can&amp;rsquo;t wait to get started!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Gearing Up for the Cascadia R Conference</title>
      <link>https://josephcarl.github.io/2017/05/gearing-up-for-the-cascadia-r-conference/</link>
      <pubDate>Fri, 12 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://josephcarl.github.io/2017/05/gearing-up-for-the-cascadia-r-conference/</guid>
      <description>&lt;p&gt;The first ever &lt;a href=&#34;https://cascadiarconf.com/&#34;&gt;Cascadia R Conference&lt;/a&gt; is less than a month away in Portland, OR, and I am excited to be attending! On top of that, I am thrilled to say my lightning talk proposal, &amp;ldquo;Building a Personal Website with Blogdown and Github Pages&amp;rdquo; has been accepted. I&amp;rsquo;ll be talking about how I built this very website in RStudio using the blogdown package. As the blogdown package is quite new, people using other static site generators like Jekyll may not know much about it. Though it&amp;rsquo;s a short talk, so it will be fairly high-level, I hope to share some of the main things I&amp;rsquo;ve learned in the process of building this site.&lt;/p&gt;

&lt;p&gt;Plus, it will be great to meet other R users from across the Pacific Northwest and learn how they are using R in their own professions to solve problems. I&amp;rsquo;m particularly looking forward to Charlotte Wickham&amp;rsquo;s &lt;code&gt;purrr&lt;/code&gt; and functional programming workshop. I have used the &lt;code&gt;map&lt;/code&gt; functions from &lt;code&gt;purrr&lt;/code&gt; a little bit in my own R programming and took Charlotte&amp;rsquo;s Datacamp course on functional programming, but haven&amp;rsquo;t done anything &amp;lsquo;crazy&amp;rsquo; with them. This should be a great workshop to learn a little bit more about ways I can incorporate &lt;code&gt;purrr&lt;/code&gt; and functional programming into my workflow.&lt;/p&gt;

&lt;p&gt;After the conference, I will be sure to post an update of it here and discuss the main things I learned, along with the slides I create for the lightning talk. Until then, my main focus is on getting through spring quarter finals.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Creating a Reproducible Workflow in R</title>
      <link>https://josephcarl.github.io/2017/04/creating-a-reproducible-workflow-in-r/</link>
      <pubDate>Fri, 21 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://josephcarl.github.io/2017/04/creating-a-reproducible-workflow-in-r/</guid>
      <description>

&lt;p&gt;For starters, I&amp;rsquo;m happy to say that I fixed the website build error I had mentioned in my first blog post. After plenty of head scratching, rereading the tutorial, and staring at my &lt;code&gt;config.toml&lt;/code&gt; file, I finally realized I had a tiny typo in my &lt;code&gt;publishDir&lt;/code&gt; file path, which prevented the documents from being copied to their new folder as expected. *facepalm*. I&amp;rsquo;m not sure how I managed to miss it the first time, but I&amp;rsquo;m glad to have it fixed now.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Having just started learning R last fall, it&amp;rsquo;s awesome to see how much I&amp;rsquo;ve learned in a short time. Though I was skeptical of R at first and nervous about its steep learning curve, I got past those reservations quickly, and some of my initial frustrations with learning it now seem trivial. I specifically remember being frustrated about sharing my code within an analysis document. I tried copying and pasting my R code into a Word document (sacrilege, I now know), and was frustrated that it did not preserve the code formatting. &lt;em&gt;But SAS does that!&lt;/em&gt;, I remember thinking. Thankfully, RStudio has made an easy fix to this problem with RMarkdown documents, plus a variety of other tools to make data analysis easy from start to finish.&lt;/p&gt;

&lt;p&gt;Through learning RMarkdown, I became interested in the idea of reproducible research. In my undergrad program in Applied Economics, the importance of replicability was often stressed, particularly after the Reinhart-Rogoff debacle with their Excel spreadsheet came to light. However, my limited quantitative work with replicability mostly centered around saving my SAS scripts and writing a &amp;lsquo;codebook&amp;rsquo; in Word to document the changes I was making and steps of my analysis. This is not a bad setup, but certainly not very efficient or easily reproducible. Now that I&amp;rsquo;m comfortable with RStudio, I have embraced the tools they&amp;rsquo;ve provided to make an integrated, reproducible workflow all within RStudio, from data intake to report writing.&lt;/p&gt;

&lt;p&gt;There are plenty of books and tutorials for the various tools RStudio provides, including RMarkdown, LaTeX integration, and git/Github. I really enjoyed the book &lt;a href=&#34;https://www.amazon.com/Reproducible-Research-Studio-Second-Chapman/dp/1498715370/ref=dp_ob_title_bk&#34;&gt;Reproducible Research in R and RStudio&lt;/a&gt; by Christopher Gandrud for a complete walkthrough of a reproducible workflow.&lt;/p&gt;

&lt;p&gt;Rather than reinvent that wheel, I&amp;rsquo;d just like to share a few key things that I&amp;rsquo;ve learned for a generally reproducible workflow in RStudio and a couple great references for those ideas. These can change somewhat depending on your specific needs and project size, but they work well for me!&lt;/p&gt;

&lt;h2 id=&#34;embrace-the-project-structure&#34;&gt;Embrace the Project Structure&lt;/h2&gt;

&lt;p&gt;Among my first noob mistakes when I began learning R was to put all my R scripts in one folder, all my datasets in another folder, and my written reports in another folder, even from different projects. As you can imagine, this quickly became a confused mess, and it was very difficult to find the files I needed. Thankfully, I quickly caught on to RStudio&amp;rsquo;s idea of &amp;lsquo;Projects&amp;rsquo;, so I could keep things organized on a project-by-project basis, whether that&amp;rsquo;s a small class assignment or a large collaborative term project.&lt;/p&gt;

&lt;h2 id=&#34;incorporate-git-github&#34;&gt;Incorporate Git/Github&lt;/h2&gt;

&lt;p&gt;Though understanding git&amp;rsquo;s system of version control seems overwhelming and complicated at first, the fact that most of its functionality exists within a few commands (&lt;code&gt;pull&lt;/code&gt;, &lt;code&gt;add&lt;/code&gt;, &lt;code&gt;commit&lt;/code&gt;, and &lt;code&gt;push&lt;/code&gt;, namely) definitely helps! Even for small projects where version control may seem unnecessary, using git and hosting your project on Github or another online repo makes it really easy to keep a backup copy for later. Plus, it&amp;rsquo;s an easy way to share your ongoing projects, like this website! RStudio has integrated git and Github functionality, so you can do your push, pull, and commits all from within RStudio. Though some tasks with the command line still make sense, if you&amp;rsquo;re just doing a simple commit and push, you can do that within RStudio with just a couple clicks! I&amp;rsquo;ve found it&amp;rsquo;s easiest to set up the Github repo at the beginning of a project, though it is possible to sync an existing project to Github and add git version control after it&amp;rsquo;s begun.&lt;/p&gt;

&lt;p&gt;For more information on incorporating git into RStudio, I&amp;rsquo;d recommend checking out &lt;a href=&#34;http://happygitwithr.com/&#34;&gt;Happy Git and GitHub for the useR&lt;/a&gt; by Jenny Bryan.&lt;/p&gt;

&lt;h2 id=&#34;divide-and-conquer&#34;&gt;Divide and Conquer&lt;/h2&gt;

&lt;p&gt;Even if you&amp;rsquo;re the only person working on a project, documenting your steps can make it easier for someone to see what you did, or even just to remind a future you looking back on it. Though I first began using R by throwing everything from reading in the data to outputting analysis and visuals into a single R script, I&amp;rsquo;ve found it can be hard to follow comments littered throughout the code.&lt;/p&gt;

&lt;p&gt;One thing that&amp;rsquo;s helped is to reduce the size of this &amp;ldquo;master script&amp;rdquo; by moving my data cleaning into a separate script, with a name like &lt;code&gt;data-preparation.R&lt;/code&gt;. This is particularly useful if you have a lot of data cleaning, reshaping, or merging datasets in your analysis. Rather than making your computer re-run the dataset creation each time you run your analysis, use a dataset preparation script to save your data as a csv or similar data file, then run your analysis on that. Similarly, if you have created any verbose functions, consider moving them to a separate script that you can source in your analysis, plus then it will already be saved in its own script for any future analyses.&lt;/p&gt;

&lt;p&gt;Separate from the master script, I use R Notebooks or an RMarkdown document for communicating my results. That way, the document has all the code necessary to recreate my analysis embedded in it, without adding the extra code from the script that I may want to save, but isn&amp;rsquo;t directly useful or necessary in my report.&lt;/p&gt;

&lt;p&gt;Additionally, now that RStudio has released its R Notebooks as of a few months ago, I now sometimes use a &amp;lsquo;master notebook&amp;rsquo; instead of a master script. Similar to Jupyter Notebooks, they offer iterative computing for experimenting with code chunks, written comments for discussing your analysis, and include output and visualizations right below each code chunk. It&amp;rsquo;s got all the benefits of writing a report with RMarkdown, but faster because you don&amp;rsquo;t have to re-knit your document to see how your output changes. R Notebooks can also easily be compiled into HTML, PDF, or Word documents to share your work. If you want to know more about R Notebooks, RStudio has &lt;a href=&#34;http://rmarkdown.rstudio.com/r_notebooks.html&#34;&gt;a great introduction&lt;/a&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;Those are some of my main ways of creating a reproducible workflow in RStudio. Of these ideas, using R Notebooks and RMarkdown documents to keep my code and analysis together have been the most useful for me. I&amp;rsquo;m sure my process will change and improve over time and as RStudio rolls out new features, but this general structure has worked well for me so far. The exact structure of a reproducible workflow will depend on the complexity of task at hand, and you may not be able to share everything on Github if you&amp;rsquo;re dealing with confidential information, but creating a reproducible workflow will help others understand your methods and help yourself in the future when looking back on your previous work!&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>First Blog Post</title>
      <link>https://josephcarl.github.io/2017/04/first-blog-post/</link>
      <pubDate>Sun, 09 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://josephcarl.github.io/2017/04/first-blog-post/</guid>
      <description>&lt;p&gt;I finally took the plunge and am attempting blogging. Specifically, as this site is directly connected to my Github, it seems like a great place to showcase some of my projects and write about my experiences as I learn data analytics. Stack Overflow and numerous blogs have come to my aid as I have been learning R and Python over the last several months, so I hope I can use this blog to share some of the things I&amp;rsquo;ve learned as well. Plus, I have never built a website before, so this is also a great learning opportunity. I may also write about some topics not directly related to data analytics as time goes on. We&amp;rsquo;ll see how it goes!&lt;/p&gt;

&lt;p&gt;This site was created with the &lt;code&gt;blogdown&lt;/code&gt; R package, RStudio, &lt;code&gt;Hugo&lt;/code&gt;, and &lt;a href=&#34;https://tclavelle.github.io/blog/blogdown_github/&#34;&gt;this&lt;/a&gt; helpful how-to guide. I am using the two-repository method described in the post. Unfortunately, I could not get my computer to recognize the &lt;code&gt;josephcarl.github.io&lt;/code&gt; folder via the &lt;code&gt;publishDir&lt;/code&gt; option in the &lt;code&gt;config.toml&lt;/code&gt; file, as described in the tutorial. I had to manually copy my files to that folder as a workaround, then commit the &lt;code&gt;josephcarl.github.io&lt;/code&gt; folder to its repo. Thankfully that doesn&amp;rsquo;t take too much work, but I&amp;rsquo;m hoping to find a better workaround soon. It&amp;rsquo;s going to be a work in progress, but I&amp;rsquo;m excited to get started!&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>